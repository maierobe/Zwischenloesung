# Hackathon 2024 - Submission of Group *Zwischenl√∂sung*

Team members: 

    - Johannes M√§rz 
    - Quentin Koplin 
    - Robert Maier 


## Description 

Im ersten Schritt der L√∂sung wird ein Machine-Vision-Ansatz angewendet, der ein Bild von einem Blechteil in ein Bin√§rbild umwandelt. Dieser Ansatz basiert auf der Bildsegmentierung "Semantic Segmentation". F√ºr die Architektur des Convolutional Neural Networks wurde U-Net gew√§hlt. 

Die optimale Position des Greifers wird auf Basis des Greiferabstands von verbotenen Bereichen (wie Bohrungen und R√§nder) und des Abstands der Greifermitte zum Bauteilschwerpunkt ermittelt. In diesem Scoring wird die Unterschreitung einer kritischen Randn√§he von 3 mm besonders stark bestraft. Mittels dynamisch an die Bauteilabma√üe angepasste Suchnetze wird in einem iterativen Prozess mit einer Coarse-Search, einer anschlie√üenden Fine-Search und einer Decimal-Search die optimale Position auf Basis der ermittelten Scores gefunden. 

![Python Version](https://img.shields.io/badge/Python-3.12-blue) 

## How to Run 

1. CV-Modell "RMS_cv_model.pth" von der Drive "ProKI-Hackathon2024-Submissions" aus der Zip-Datei "Team-Zwischenloesung-CV-Modell" laden und in den Solution-Ordner legen.
2. Ausf√ºhren von `python solution/main.py path/to/input/tasks.csv output/solutions.csv` in der CMD.

## ‚ú® Besondere Funktionen unserer L√∂sung 

### Greifermittelpunkt (**Wichtig**)

Die Optimierung der Positionierung erfolgt zum **Bauteilschwerpunkt** und nicht dem Bildmittelpunkt. Diese Optimierung ist bewusst nicht auf die Aufgabenstellung ausgerichtet, sondern auf das reale Problem. Da der Schwerpunkt in unserer L√∂sung die tats√§chliche physikalische Balance der vorhandenen Bauteilgeometrie ber√ºcksichtigt, werden pr√§ziseres und sicheres Greifen mit niedrigen Kippmomenten auf den Greifarm erm√∂glicht.  

### Zus√§tzliche Parameter zur Positionsoptimierung

Diese k√∂nnen verwendet werden, je nach Anforderung (Bspw Mindestabstand zum Rand), um die Positionierung des Greifers zu verbessern. Das ist m√∂glich in der Funktion **main_get_position_and_visualization() in helper_positioning.py** 

- Randbereich (**min_distance_to_forbidden_area**): Definiert den Randbereich den der Greifer bestenfalls einhalten soll. Eine Positionierung in diesem Bereich wird in der Positionssuche nicht ausgeschlossen, aber durch st√§rkere Bestrafung vermieden, wenn m√∂glich. Der Abstand kann abh√§ngig der Bauteileigenschaften oder Anforderungen gew√§hlt werden. 
- Rechenaufwand der Positionierung (**num_iter**): Der Rechenaufwand kann durch die Variable **search_param_num_iter** erheblich beeinflusst werden. Die vorliegende Variable determiniert die Aufl√∂sung des Netzes f√ºr die Positionierung. Eine Erh√∂hung der Variablen f√ºhrt zu einer Verfeinerung des Netzes und somit zu einer erh√∂hten Anzahl an Positionsl√∂sungen. Allerdings ist auch ein Anstieg des Rechenaufwands zu verzeichnen. 

### Visualisierung

Im output-Ordner wird zu jedem Bauteil-Greifer-Paar eine Visualisierung der gefundenen Position abgespeichert. Darin sind neben dem Greifer auch der Greifermittelpunkt, der Bauteilschwerpunkt sowie die Positionierungsparameter (x, y, Winkel) zu erkennen. 

<img src="images/result___part_2___gripper_1%20(1).png" alt="" width="300px" />

### Warnings und Errors

Die gefundene Greiferpositionierung wird in unserem Algorithmus auf kritische Eigenschaften, wie bspw. die N√§he zu Randbereichen, gepr√ºft. Warnungen werden in rot oder gelb im Terminal ausgegeben und in der Visualisierungs-png abgespeichert. Zudem ist in der Ergebnis-csv-Datei eine weitere Spalte mit dem key ‚Äúannotation‚Äù vorhanden, in der diese Warnungen zu finden sind. Folgende Warnungen sind m√∂glich:  

- There are some gripper points outside of the part. Check Position of gripper in the visualization image. [ROT] 
- There are some gripper points near the edge (<3mm). [GELB] 
- Distance between gripper center and part center of mass is high. Check if gripper force can safely compensate the tilting moment. [GELB]


<img src="images/result___binary_mask_4___gripper_1.png" alt="" width="300px" />

### Gripper Dateiformat

Sowohl PNG- als auch SVG-Dateien k√∂nnen verarbeitet werden. 


## üéØ Funktionsweise der Positionierung und Scoring 

Der Positionierungsalgorithmus basiert auf einem Scoring-System mit verschiedenen linearen und nichtlinearen Einflussparametern. In diesem Scoring wird jeder einzelne Greiferpunkt bewertet und schlie√ülich die Summe der Einzelscores gebildet.  

Belohnt wird folgender Einflussparameter: 

- Abstand des Greiferpunkt-Rands vom n√§chstgelegenen verbotenen Bereich: Bis zu einer Schwelle von 5mm steigt dieser Wert proportional an und anschlie√üend mit einer ged√§mpften Steigung (Faktor 0.15). So wird eine Entfernung vom Bauteil-Randbereich belohnt, und gleichzeitig die Positionierung in der Mitte gro√üer freier Bauteilfl√§chen nicht √ºberm√§√üig bevorzugt. Dieser Einflussfaktor kann in einer Distanzkarte visualisiert werden (siehe Abbildung unten links)

	<img src="images/result___part_2___gripper_1.png" alt="" width="300px" /> <img src="images/result___part_4___gripper_5.png" alt="" width="300px" />

- Bestraft werden dagegen:

	- Euklidische Distanz zwischen Greifermittelpunkt und Bildschwerpunkt: So werden Kippmomente auf den Greifer m√∂glichst reduziert. Der Bildschwerpunkt wird aus Bauteilgeometrie ermittelt, die von unserem Computer-Vision-Modell in Form einer Maske erkannt wird. Bohrungen und Ausstanzungen werden hier also ber√ºcksichtigt. 
	- N√§he zum verbotenen Bereich < 3mm: In diesem Randbereich wird eine zus√§tzliche Bestrafung vorgenommen, wodurch ein Sicherheitsabstand bevorzugt wird. So k√∂nnen Ungenauigkeiten (bspw. In der Bewegung und Positionierung des Greifarms) ber√ºcksichtig werden. Der Parameter (min_distance_to_forbidden_area) kann ge√§ndert werden. 
	- Out of boundary: Ragen Greiferpunkte in den als verboten identifizierten Bereich, so wird eine enorm hohe Bestrafung durchgef√ºhrt. So werden diese Positionen nur ausgew√§hlt, wenn keine andere M√∂glichkeit besteht.  

Um die optimale Greiferposition m√∂glichst effizient zu finden, wird die Suche in drei Stufen unterteilt: 

- In der Coarse-Search wird ein grob diskretisierter dreidimensionaler Raum aus x, y und Winkel aufgespannt. F√ºr diese Positionen wird jeweils ein vorl√§ufiger Score ermittelt. An der vielversprechendsten Stelle wird dann in einem bestimmten Suchraum eine Fine-Search durchgef√ºhrt. 
- Die Fine-Search pr√ºft einen dynamisch an das Netz der groben Suche angepassten Suchbereich auf die optimale L√∂sung. Dabei wird mit einer Genauigkeit von 1px bzw. 1grad iteriert. 
- Schlie√ülich wird bei der Decimal-Search im Bereich um die beste L√∂sung der Fine-Search gesucht und die erste Nachkommastelle der optimalen Greiferposition bestimmt. 

Zur Bestimmung der Netzaufl√∂sung von Coarse- und Fine-Search ist ein Algorithmus implementiert, der abh√§ngig von Greifergr√∂√üe, Anzahl Greiferpunkte, Bauteilgr√∂√üe und gew√ºnschtem Rechenaufwand (search_param_num_iter) die Suchr√§ume diskretisiert. So kann bei verschiedensten Kombinationen von Greifern und Bauteilen eine n√§herungsweise konstante Berechnungszeit gew√§hrleistet werden. Dies geschieht, indem mathematische Zusammenh√§nge zwischen dem Rechenaufwand und der Netzaufl√∂sung sowie der Greiferkomplexit√§t aufgel√∂st werden und eine feste Beziehung zwischen den Netzen der Coarse- und Fine-Search festgelegt ist. 
 

## ü§ñ Modellparameter vom Computer Vision Ansatz 

Modellarchitektur (U-Net mit EfficientNet-B7 als Encoder): 

Aufgrund ihrer bew√§hrten Leistung in Bildsegmentierungsaufgaben wurde die U-Net-Architektur gew√§hlt. Sie erm√∂glicht die Extraktion sowohl globaler als auch lokaler Merkmale, die f√ºr die Bearbeitung von verrauschten und variierenden Bildern essenziell sind. Die Integration des Encoders EfficientNet-B7 erfolgte unter anderem aufgrund seiner hohen Kapazit√§t und Effizienz, die ihn f√ºr die Extraktion von Merkmalen aus komplexen und hochdimensionalen Bilddaten pr√§destinieren. Dies unterst√ºtzt die Bew√§ltigung der Bildvariabilit√§t und erm√∂glicht eine robuste Segmentierung trotz vorhandener St√∂rungen. 

Optimizer (RMSprop): 

Die Wahl von RMSprop als Optimizer erfolgte aufgrund seiner spezifischen F√§higkeit, insbesondere bei verrauschten Gradienten, eine konsistente und effiziente Optimierung zu gew√§hrleisten. Dies ist von besonderer Relevanz, da bei stark verrauschten und unscharfen Bildern die Gradienten h√§ufig uneinheitlich sind. 

Aktivierungsfunktion (Sigmoid): 

Die Verwendung der Sigmoid-Aktivierungsfunktion am Ende des Modells f√∂rdert die bin√§re Segmentierung der Labels. Die Anwendung dieser Funktion erm√∂glicht die pr√§zise Vorhersage von Wahrscheinlichkeiten f√ºr die Zugeh√∂rigkeit zu einer bestimmten Klasse, was in diesem Fall einen wesentlichen Beitrag zur Kantenerkennung leistet. 

Loss-Funktion (JaccardLoss): 

Die Jaccard-Loss-Funktion wurde ausgew√§hlt, da sie sich f√ºr Segmentierungsaufgaben mit ungleichen Klassenverteilungen als geeignet erwiesen hat. Sie maximiert die √Ñhnlichkeit zwischen den vorhergesagten Segmenten und den tats√§chlichen Labels und gleicht dabei die Auswirkungen von verrauschten oder unvollst√§ndigen Label-Definitionen aus. 


## Disclaimer 

Bei der initialen Ausf√ºhrung des Modells ist mit einer l√§ngeren Ladezeit zu rechnen. Dieser Vorgang umfasst das Laden der Parameter, des Modells und der Funktionen.  
Bei der Verwendung eines Laptops ist darauf zu achten, dass dieser nicht im Energiesparmodus oder Batteriebetrieb, sondern an das Netz angeschlossen ist. Andernfalls erh√∂ht sich die Berechnungszeit um ein Vielfaches. 

Unsere Ausf√ºhrungszeiten:  

Laptop ‚Äì Intel i5 11th Gen (2020) - keine GPU: ~2 Sekunden pro Greifer-Bauteil-Paar

Falls die Ausf√ºhrungszeit bei Ihrem Rechner >3 Sekunden betr√§gt, verringern Sie die Variable search_param_num_iter in der Funktion main_get_position_and_visualization() in  solution/helper_positioning.py

